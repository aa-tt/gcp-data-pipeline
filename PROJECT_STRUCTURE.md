# GCP Data Pipeline - Project Structure

```
gcp-data-pipeline/
â”œâ”€â”€ README.md                          # Main documentation
â”œâ”€â”€ SETUP.md                           # Detailed setup guide
â”œâ”€â”€ ARCHITECTURE.md                    # Architecture diagrams
â”œâ”€â”€ COST_ANALYSIS.md                   # Cost breakdown and optimization
â”œâ”€â”€ QUICK_REFERENCE.md                 # Command cheatsheet
â”œâ”€â”€ SUMMARY.md                         # Complete solution summary
â”œâ”€â”€ LICENSE                            # MIT License
â”œâ”€â”€ .gitignore                         # Git ignore patterns
â”‚
â”œâ”€â”€ terraform/                         # Infrastructure as Code
â”‚   â”œâ”€â”€ main.tf                        # Main Terraform configuration
â”‚   â”œâ”€â”€ variables.tf                   # Variable definitions
â”‚   â”œâ”€â”€ outputs.tf                     # Output values
â”‚   â”œâ”€â”€ terraform.tfvars.example       # Example variables file
â”‚   â”‚
â”‚   â””â”€â”€ modules/                       # Terraform modules
â”‚       â”œâ”€â”€ storage/                   # Cloud Storage buckets
â”‚       â”‚   â”œâ”€â”€ main.tf
â”‚       â”‚   â”œâ”€â”€ variables.tf
â”‚       â”‚   â””â”€â”€ outputs.tf
â”‚       â”‚
â”‚       â”œâ”€â”€ pubsub/                    # Pub/Sub topics & subscriptions
â”‚       â”‚   â”œâ”€â”€ main.tf
â”‚       â”‚   â”œâ”€â”€ variables.tf
â”‚       â”‚   â””â”€â”€ outputs.tf
â”‚       â”‚
â”‚       â”œâ”€â”€ bigquery/                  # BigQuery datasets & tables
â”‚       â”‚   â”œâ”€â”€ main.tf
â”‚       â”‚   â”œâ”€â”€ variables.tf
â”‚       â”‚   â””â”€â”€ outputs.tf
â”‚       â”‚
â”‚       â”œâ”€â”€ cloud-functions/           # Cloud Functions
â”‚       â”‚   â”œâ”€â”€ main.tf
â”‚       â”‚   â”œâ”€â”€ variables.tf
â”‚       â”‚   â””â”€â”€ outputs.tf
â”‚       â”‚
â”‚       â”œâ”€â”€ dataproc/                  # Dataproc Serverless config
â”‚       â”‚   â”œâ”€â”€ main.tf
â”‚       â”‚   â”œâ”€â”€ variables.tf
â”‚       â”‚   â””â”€â”€ outputs.tf
â”‚       â”‚
â”‚       â””â”€â”€ composer/                  # Cloud Composer (Airflow)
â”‚           â”œâ”€â”€ main.tf
â”‚           â”œâ”€â”€ variables.tf
â”‚           â””â”€â”€ outputs.tf
â”‚
â”œâ”€â”€ functions/                         # Cloud Function source code
â”‚   â”œâ”€â”€ data-ingestion/                # HTTP-triggered ingestion
â”‚   â”‚   â”œâ”€â”€ main.py                    # Function code
â”‚   â”‚   â””â”€â”€ requirements.txt           # Python dependencies
â”‚   â”‚
â”‚   â””â”€â”€ pubsub-processor/              # Event-triggered processing
â”‚       â”œâ”€â”€ main.py                    # Function code
â”‚       â””â”€â”€ requirements.txt           # Python dependencies
â”‚
â”œâ”€â”€ pyspark-jobs/                      # PySpark ETL jobs
â”‚   â”œâ”€â”€ etl_transform.py               # Main ETL job
â”‚   â””â”€â”€ requirements.txt               # Python dependencies
â”‚
â”œâ”€â”€ airflow-dags/                      # Airflow DAGs
â”‚   â””â”€â”€ data_pipeline_dag.py           # Main orchestration DAG
â”‚
â”œâ”€â”€ scripts/                           # Utility scripts
â”‚   â”œâ”€â”€ deploy.sh                      # One-command deployment
â”‚   â”œâ”€â”€ test.sh                        # Testing script
â”‚   â””â”€â”€ cleanup.sh                     # Resource cleanup
â”‚
â””â”€â”€ .github/                           # GitHub Actions CI/CD
    â””â”€â”€ workflows/
        â””â”€â”€ deploy.yml                 # Deployment workflow
```

## File Descriptions

### Documentation Files

| File | Purpose | When to Use |
|------|---------|-------------|
| `README.md` | Overview, quick start, architecture | First file to read |
| `SETUP.md` | Detailed setup instructions | When deploying for first time |
| `ARCHITECTURE.md` | System design and diagrams | Understanding the system |
| `COST_ANALYSIS.md` | Cost estimates and optimization | Budget planning |
| `QUICK_REFERENCE.md` | Command cheatsheet | Daily operations |
| `SUMMARY.md` | Complete solution overview | Executive summary |

### Infrastructure (Terraform)

| File | Purpose | Modify When |
|------|---------|-------------|
| `terraform/main.tf` | Root configuration | Adding new resources |
| `terraform/variables.tf` | Input variables | Changing defaults |
| `terraform/outputs.tf` | Output values | Need new outputs |
| `terraform/terraform.tfvars.example` | Example config | Sharing template |
| `terraform/modules/*/` | Resource modules | Customizing components |

### Application Code

| File | Purpose | Modify When |
|------|---------|-------------|
| `functions/data-ingestion/main.py` | HTTP data ingestion | Changing ingestion logic |
| `functions/pubsub-processor/main.py` | Pub/Sub processing | Changing validation rules |
| `pyspark-jobs/etl_transform.py` | PySpark ETL | Changing transformations |
| `airflow-dags/data_pipeline_dag.py` | Airflow orchestration | Changing schedule/workflow |

### Operational Scripts

| File | Purpose | When to Use |
|------|---------|-------------|
| `scripts/deploy.sh` | Deploy everything | Initial setup, updates |
| `scripts/test.sh` | Test components | After deployment, debugging |
| `scripts/cleanup.sh` | Delete resources | Teardown, cleanup |

### CI/CD

| File | Purpose | When to Use |
|------|---------|-------------|
| `.github/workflows/deploy.yml` | GitHub Actions | Automated deployments |

## Lines of Code

```
Configuration (Terraform):     ~1,200 lines
Application Code (Python):     ~800 lines
Documentation (Markdown):      ~1,500 lines
Scripts (Bash):                ~200 lines
CI/CD (YAML):                  ~250 lines
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL:                         ~3,950 lines
```

## Module Dependencies

```
terraform/main.tf
    â”œâ”€â”€ modules/storage          (4 buckets)
    â”œâ”€â”€ modules/pubsub           (4 topics, 4 subscriptions)
    â”œâ”€â”€ modules/bigquery         (1 dataset, 3 tables, 1 view)
    â”œâ”€â”€ modules/cloud-functions  (2 functions)
    â”‚       â””â”€â”€ depends on: storage, pubsub
    â”œâ”€â”€ modules/dataproc         (serverless config)
    â”‚       â””â”€â”€ depends on: storage
    â””â”€â”€ modules/composer         (optional)
            â””â”€â”€ depends on: storage, pubsub, bigquery
```

## Data Flow Through Files

```
1. Data Ingestion:
   HTTP Request â†’ functions/data-ingestion/main.py â†’ Pub/Sub

2. Event Processing:
   Pub/Sub â†’ functions/pubsub-processor/main.py â†’ Cloud Storage

3. Batch Processing:
   airflow-dags/data_pipeline_dag.py (schedules)
       â†’ pyspark-jobs/etl_transform.py (processes)
       â†’ BigQuery (stores)

4. Infrastructure:
   terraform/main.tf (provisions)
       â†’ All modules (creates resources)
       â†’ GCP (deployed)

5. CI/CD:
   GitHub Push â†’ .github/workflows/deploy.yml (runs)
       â†’ terraform/ (deploys infrastructure)
       â†’ functions/ (deploys functions)
       â†’ pyspark-jobs/ (uploads jobs)
```

## Configuration Files

### Terraform Variables (terraform.tfvars)
```hcl
project_id  = "your-project-id"
region      = "us-central1"
environment = "dev"
enable_composer = false
```

### Environment Variables (.env or shell)
```bash
GCP_PROJECT_ID="your-project-id"
GCP_REGION="us-central1"
ENVIRONMENT="dev"
```

### GitHub Secrets
```
GCP_PROJECT_ID    # Your GCP project ID
GCP_SA_KEY        # Service account key (base64)
GCP_REGION        # Deployment region
```

## Resource Naming Convention

All resources follow this pattern:
```
{project_id}-{resource_type}-{environment}
```

Examples:
- `my-project-raw-data-dev` (Cloud Storage bucket)
- `data-pipeline-sa-dev` (Service account)
- `raw-data-topic-dev` (Pub/Sub topic)
- `data_warehouse_dev` (BigQuery dataset)

## Getting Started Checklist

1. âœ… Clone/download this repository
2. âœ… Review `README.md` for overview
3. âœ… Read `SETUP.md` for detailed instructions
4. âœ… Set environment variables
5. âœ… Copy `terraform.tfvars.example` to `terraform.tfvars`
6. âœ… Update `terraform.tfvars` with your values
7. âœ… Run `terraform init` and `terraform apply`
8. âœ… Run `./scripts/deploy.sh dev`
9. âœ… Run `./scripts/test.sh dev`
10. âœ… Check `QUICK_REFERENCE.md` for commands

## Customization Points

### High Priority (Likely to Change)
- âœï¸ `pyspark-jobs/etl_transform.py` - Your transformation logic
- âœï¸ `terraform/terraform.tfvars` - Your project settings
- âœï¸ `functions/data-ingestion/main.py` - Your validation rules

### Medium Priority (May Change)
- âœï¸ `terraform/modules/bigquery/main.tf` - Your table schema
- âœï¸ `airflow-dags/data_pipeline_dag.py` - Your schedule
- âœï¸ `terraform/variables.tf` - Resource sizing

### Low Priority (Usually Don't Change)
- ğŸ“Œ `terraform/modules/*/main.tf` - Infrastructure setup
- ğŸ“Œ `.github/workflows/deploy.yml` - CI/CD pipeline
- ğŸ“Œ `scripts/*.sh` - Operational scripts

## Total Resource Count

When fully deployed, you'll have:

- **Cloud Storage**: 4-5 buckets
- **Pub/Sub**: 4 topics, 4 subscriptions
- **BigQuery**: 1 dataset, 3 tables, 1 view
- **Cloud Functions**: 2 functions
- **IAM**: 1 service account + roles
- **Cloud Scheduler**: 1 job
- **Cloud Composer**: 1 environment (optional)
- **Monitoring**: Automatic dashboards and logs

**Total: ~20-25 GCP resources**

## Maintenance Files

Files you'll interact with regularly:

**Daily:**
- `QUICK_REFERENCE.md` - Command reference
- CloudConsole logs and monitoring

**Weekly:**
- `pyspark-jobs/etl_transform.py` - Update transformations
- `airflow-dags/data_pipeline_dag.py` - Adjust schedules

**Monthly:**
- `COST_ANALYSIS.md` - Review costs
- `terraform/variables.tf` - Optimize resources

**Quarterly:**
- `ARCHITECTURE.md` - Review architecture
- All documentation - Keep up to date
